{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "#from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, fbeta_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Subsampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data')\n",
    "\n",
    "X = pd.read_csv('X_3specialties_equalWeight_subsample.zip',compression='zip', index_col=False)\n",
    "y = pd.read_csv('y_3specialties_equalWeight_subsample.zip',compression='zip')\n",
    "groups = pd.read_csv('groups_3specialties_equalWeight_subsample.zip',compression='zip')\n",
    "\n",
    "X = X.iloc[:,1:]\n",
    "y = y.iloc[:,1:]\n",
    "groups = groups.iloc[:,1:]\n",
    "\n",
    "y_columns = y.columns\n",
    "\n",
    "#le = LabelEncoder()\n",
    "#y = y.values.ravel()\n",
    "#y = le.fit_transform(y)\n",
    "#y = pd.DataFrame(y)\n",
    "#y.columns = y_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Imputation and without Regulariztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_LogReg_noPenalty_kfold(X, y, groups, random_state,n_folds):\n",
    "    # create a test set\n",
    "    \n",
    "    splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=random_state)\n",
    "    \n",
    "    for i_other,i_test in splitter.split(X, y, groups):\n",
    "        X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "        X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "        \n",
    "    kf = GroupKFold(n_splits=n_folds)\n",
    "    \n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    \n",
    "    categorical_ftrs = ['Prscrbr_City','Prscrbr_State_Abrvtn','Brnd_Name','Gnrc_Name']\n",
    "\n",
    "    std_ftrs = ['Tot_Clms',  'Tot_30day_Fills', 'Tot_Day_Suply', 'Tot_Drug_Cst', \n",
    "                'Tot_Benes', 'GE65_Tot_Clms', 'GE65_Tot_30day_Fills', 'GE65_Tot_Drug_Cst',\n",
    "                'GE65_Tot_Day_Suply', 'GE65_Tot_Benes']\n",
    "    \n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(estimator = LinearRegression(), \n",
    "                                    random_state=random_state,max_iter=1000)),\n",
    "    ('scaler', StandardScaler())])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'))])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('num', numeric_transformer, std_ftrs),\n",
    "        ('onehot', categorical_transformer, categorical_ftrs)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "\n",
    "\n",
    "    final_scaler = StandardScaler()\n",
    "    \n",
    "    pipe = make_pipeline(preprocessor,final_scaler, LogisticRegression(max_iter=10000))\n",
    "    \n",
    "    # the parameter(s) we want to tune\n",
    "\n",
    "    \n",
    "    param_grid = {'logisticregression__solver': ['saga'],\n",
    "                  'logisticregression__penalty' : ['none']}\n",
    "                   \n",
    "    \n",
    "    \n",
    "    #f05_scorer = make_scorer(fbeta_score, beta=0.5, average = 'macro')\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, \n",
    "                        param_grid=param_grid,\n",
    "                        scoring = 'accuracy',\n",
    "                        cv=kf, \n",
    "                        return_train_score = True,\n",
    "                        verbose=10)\n",
    "    \n",
    "    # do kfold CV on _other\n",
    "    \n",
    "    grid_result = grid.fit(X_other, y_other.values.ravel(), groups=groups_other)\n",
    "    \n",
    "    #feature_names = grid.best_estimator_[0].get_feature_names_out()\n",
    "    \n",
    "    print()\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    \n",
    "    print(f'Best params: {grid.best_params_}')\n",
    "    \n",
    "    print(f\"mean CV: {means} +/ {stds}\")\n",
    "    \n",
    "    y_test_pred_proba = grid.predict_proba(X_test)\n",
    "    \n",
    "    y_test_pred = grid.predict(X_test)\n",
    "    \n",
    "    #score = accuracy_score(y_test,y_test_pred)\n",
    "    \n",
    "    feature_names = std_ftrs + list(grid.best_estimator_[0].named_transformers_['onehot'][0].get_feature_names(categorical_ftrs))\n",
    "    \n",
    "    f_05_score = fbeta_score(y_test, y_test_pred, beta = 0.5, labels=sorted(np.unique(y)), average='macro')\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(\"accuracy:\", accuracy)\n",
    "    \n",
    "    \n",
    "    return grid, X_test, y_test, f_05_score, cm, accuracy, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "final_models_list = []\n",
    "test_scores = []\n",
    "best_params = []\n",
    "confusion_mat = []\n",
    "class_met = []\n",
    "accuracy_scores = []\n",
    "final_models = []\n",
    "X_test_set_list =[]\n",
    "y_test_set_list =[]\n",
    "featname_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Random State # {i}')\n",
    "    print()\n",
    "    \n",
    "    fin_grid, X_test_set, y_test_set, test_score,cmat, acc, feat_names = ML_LogReg_noPenalty_kfold(X, y, groups, 42*i , 4)\n",
    "    \n",
    "    #featname_list.append(featname)\n",
    "    \n",
    "    X_test_set_list.append(X_test_set)\n",
    "    \n",
    "    y_test_set_list.append(y_test_set)\n",
    "    \n",
    "    final_models_list.append(fin_grid)\n",
    "    \n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    confusion_mat.append(cmat)\n",
    "\n",
    "    accuracy_scores.append(acc)\n",
    "    \n",
    "    featname_list.append(feat_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_scores)\n",
    "print(np.mean(accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../results')\n",
    "file = open('LogReg_noPenalty_grid.save', 'wb')\n",
    "\n",
    "pickle.dump((X_test_set_list, \n",
    "             y_test_set_list,\n",
    "             final_models_list,\n",
    "             confusion_mat,\n",
    "             test_scores,\n",
    "             accuracy_scores,\n",
    "             featname_list),file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Imputation and Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_LogReg_L1_kfold(X, y, groups, random_state,n_folds):\n",
    "    # create a test set\n",
    "    \n",
    "    splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=random_state)\n",
    "    \n",
    "    for i_other,i_test in splitter.split(X, y, groups):\n",
    "        X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "        X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "        \n",
    "    kf = GroupKFold(n_splits=n_folds)\n",
    "    \n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    \n",
    "    categorical_ftrs = ['Prscrbr_City','Prscrbr_State_Abrvtn','Brnd_Name','Gnrc_Name']\n",
    "\n",
    "    std_ftrs = ['Tot_Clms',  'Tot_30day_Fills', 'Tot_Day_Suply', 'Tot_Drug_Cst', \n",
    "                'Tot_Benes', 'GE65_Tot_Clms', 'GE65_Tot_30day_Fills', 'GE65_Tot_Drug_Cst',\n",
    "                'GE65_Tot_Day_Suply', 'GE65_Tot_Benes']\n",
    "    \n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(estimator = LinearRegression(), \n",
    "                                    random_state=random_state,max_iter=1000)),\n",
    "    ('scaler', StandardScaler())])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'))])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('num', numeric_transformer, std_ftrs),\n",
    "        ('onehot', categorical_transformer, categorical_ftrs)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "\n",
    "\n",
    "    final_scaler = StandardScaler()\n",
    "    \n",
    "    pipe = make_pipeline(preprocessor,final_scaler, LogisticRegression(max_iter=10000))\n",
    "    \n",
    "    # the parameter(s) we want to tune\n",
    "\n",
    "    \n",
    "    param_grid = {'logisticregression__solver': ['saga'],\n",
    "                  'logisticregression__penalty' : ['l1'], \n",
    "                  'logisticregression__C'       : np.logspace(-3,3,7)}\n",
    "                   \n",
    "    \n",
    "    \n",
    "    #f05_scorer = make_scorer(fbeta_score, beta=0.5, average = 'macro')\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, \n",
    "                        param_grid=param_grid,\n",
    "                        scoring = 'accuracy',\n",
    "                        cv=kf, \n",
    "                        return_train_score = True, \n",
    "                        n_jobs=8, \n",
    "                        verbose=10)\n",
    "    \n",
    "    # do kfold CV on _other\n",
    "    \n",
    "    grid_result = grid.fit(X_other, y_other.values.ravel(), groups=groups_other)\n",
    "    \n",
    "    #feature_names = grid.best_estimator_[0].get_feature_names_out()\n",
    "    \n",
    "    print()\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    \n",
    "    print(f'Best params: {grid.best_params_}')\n",
    "    \n",
    "    print(f\"mean CV: {means} +/ {stds}\")\n",
    "    \n",
    "    y_test_pred_proba = grid.predict_proba(X_test)\n",
    "    \n",
    "    y_test_pred = grid.predict(X_test)\n",
    "    \n",
    "    #score = accuracy_score(y_test,y_test_pred)\n",
    "    \n",
    "    feature_names = std_ftrs + list(grid.best_estimator_[0].named_transformers_['onehot'][0].get_feature_names(categorical_ftrs))\n",
    "    \n",
    "    f_05_score = fbeta_score(y_test, y_test_pred, beta = 0.5, labels=sorted(np.unique(y)), average='macro')\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(\"accuracy:\", accuracy)\n",
    "    \n",
    "    \n",
    "    return grid, X_test, y_test, f_05_score, cm, accuracy, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "final_models_list = []\n",
    "test_scores = []\n",
    "best_params = []\n",
    "confusion_mat = []\n",
    "class_met = []\n",
    "accuracy_scores = []\n",
    "final_models = []\n",
    "X_test_set_list =[]\n",
    "y_test_set_list =[]\n",
    "featname_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Random State # {i}')\n",
    "    print()\n",
    "    \n",
    "    fin_grid, X_test_set, y_test_set, test_score,cmat, acc, feat_names = ML_LogReg_L1_kfold(X, y, groups, 42*i , 4)\n",
    "    \n",
    "    #featname_list.append(featname)\n",
    "    \n",
    "    X_test_set_list.append(X_test_set)\n",
    "    \n",
    "    y_test_set_list.append(y_test_set)\n",
    "    \n",
    "    final_models_list.append(fin_grid)\n",
    "    \n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    confusion_mat.append(cmat)\n",
    "\n",
    "    accuracy_scores.append(acc)\n",
    "    \n",
    "    featname_list.append(feat_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save results with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../results')\n",
    "file = open('LogReg_L1_grid.save', 'wb')\n",
    "\n",
    "pickle.dump((X_test_set_list, \n",
    "             y_test_set_list,\n",
    "             final_models_list,\n",
    "             confusion_mat,\n",
    "             test_scores,\n",
    "             accuracy_scores,\n",
    "             featname_list),file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Coefficients for Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefs = grid.best_estimator_[2].coef_[0]\n",
    "sorted_indcs = np.argsort(np.abs(coefs))\n",
    "ftr_names = np.array(ftr_names)\n",
    "\n",
    "plt.figure(figsize=(6.4,4.8))\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "plt.barh(np.arange(20),coefs[sorted_indcs[-20:]])\n",
    "plt.yticks(np.arange(20),ftr_names[sorted_indcs[-20:]])\n",
    "plt.xlabel('coefficient')\n",
    "plt.title('Logistic Regression (L1) Coefficients (After Scaling)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('LRC_coefs_scaled.png',dpi=1200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data1030",
   "language": "python",
   "name": "data1030"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
