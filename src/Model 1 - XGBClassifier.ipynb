{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer, log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_ftrs = ['Prscrbr_City',\n",
    "                    'Prscrbr_State_Abrvtn',\n",
    "                    'Brnd_Name',\n",
    "                    'Gnrc_Name']\n",
    "\n",
    "std_ftrs = ['Tot_Clms', \n",
    "            'Tot_30day_Fills', \n",
    "            'Tot_Day_Suply', \n",
    "            'Tot_Drug_Cst', \n",
    "            'Tot_Benes', \n",
    "            'GE65_Tot_Clms',\n",
    "            'GE65_Tot_30day_Fills',\n",
    "            'GE65_Tot_Drug_Cst',\n",
    "            'GE65_Tot_Day_Suply',\n",
    "            'GE65_Tot_Benes']                                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../data')\n",
    "X = pd.read_csv('X_3specialties_equalWeight_subsample.zip',compression='zip', index_col=False)\n",
    "y = pd.read_csv('y_3specialties_equalWeight_subsample.zip',compression='zip')\n",
    "groups = pd.read_csv('groups_3specialties_equalWeight_subsample.zip',compression='zip')\n",
    "\n",
    "X = X.iloc[:,1:]\n",
    "y = y.iloc[:,1:]\n",
    "groups = groups.iloc[:,1:]\n",
    "y_columns = y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label encoder\n",
    "le = LabelEncoder()\n",
    "y = y.values.ravel()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "\n",
    "y = pd.DataFrame(y)\n",
    "y.columns = y_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integer mapping\n",
    "integer_mapping = {l: i for i, l in enumerate(le.classes_)}\n",
    "print(integer_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_XGBpipeline_kfold(X, y, groups, random_state,n_folds):\n",
    "    # create a test set\n",
    "    \n",
    "    splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=random_state)\n",
    "    \n",
    "    for i_other,i_test in splitter.split(X, y, groups):\n",
    "        X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "        X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "        \n",
    "    kf = GroupKFold(n_splits=n_folds)\n",
    "    \n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    \n",
    "    categorical_ftrs = ['Prscrbr_City','Prscrbr_State_Abrvtn','Brnd_Name','Gnrc_Name']\n",
    "\n",
    "    std_ftrs = ['Tot_Clms',  'Tot_30day_Fills', 'Tot_Day_Suply', 'Tot_Drug_Cst', \n",
    "                'Tot_Benes', 'GE65_Tot_Clms', 'GE65_Tot_30day_Fills', 'GE65_Tot_Drug_Cst',\n",
    "                'GE65_Tot_Day_Suply', 'GE65_Tot_Benes']\n",
    "    \n",
    "\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "    #('imputer', IterativeImputer(estimator = LinearRegression(), \n",
    "    #                                random_state=random_state,max_iter=200)),\n",
    "    ('scaler', StandardScaler())])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'))])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('num', numeric_transformer, std_ftrs),\n",
    "        ('onehot', categorical_transformer, categorical_ftrs)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "\n",
    "    \n",
    "    clf = xgb.XGBClassifier(num_class=3,\n",
    "                                eval_metric = \"mlogloss\",\n",
    "                                objective = \"multi:softprob\",\n",
    "                                random_state = random_state, \n",
    "                                use_label_encoder = False)\n",
    "\n",
    "\n",
    "    pipe = make_pipeline(preprocessor,clf)\n",
    "    \n",
    "    # the parameter(s) we want to tune\n",
    "\n",
    "    \n",
    "    param_grid = {\n",
    "              \"xgbclassifier__missing\": [np.nan],\n",
    "              \"xgbclassifier__max_depth\": [3, 10, 30, 100, 300],\n",
    "              \"xgbclassifier__learning_rate\": [0.01, 0.1],\n",
    "              \"xgbclassifier__n_estimators\": [300,500],\n",
    "              \"xgbclassifier__colsample_bytree\": [0.5, 0.7, 0.9],\n",
    "              \"xgbclassifier__seed\": [random_state]  }\n",
    "    \n",
    "    \n",
    "    #f05_scorer = make_scorer(fbeta_score, beta=0.5, average = 'macro')\n",
    "    # prepare gridsearch\n",
    "    \n",
    "    \n",
    "    grid = GridSearchCV(pipe, \n",
    "                        param_grid=param_grid,\n",
    "                        scoring = 'accuracy',\n",
    "                        cv=kf, \n",
    "                        return_train_score = True, \n",
    "                        n_jobs= 1, \n",
    "                        verbose=10)\n",
    "    \n",
    "    # do kfold CV on _other\n",
    "    \n",
    "    grid_result = grid.fit(X_other, y_other.values.ravel(), groups=groups_other)\n",
    "    \n",
    "    feature_names = std_ftrs + list(grid.best_estimator_[0].named_transformers_['onehot'][0].get_feature_names(categorical_ftrs))\n",
    "    \n",
    "    print()\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    \n",
    "    print(f'Best params: {grid.best_params_}')\n",
    "    \n",
    "    print(f\"mean CV: {np.mean(means)} +/ {np.mean(stds)}\")\n",
    "    \n",
    "    y_test_pred_proba = grid.predict_proba(X_test)\n",
    "    \n",
    "    y_test_pred = grid.predict(X_test)\n",
    "    \n",
    "    #score = accuracy_score(y_test,y_test_pred)\n",
    "    \n",
    "    f_05_score = fbeta_score(y_test, y_test_pred, beta = 0.5, labels=sorted(np.unique(y)), average='macro')\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    print(\"accuracy:\", accuracy)\n",
    "    print()\n",
    "    \n",
    "    return grid, X_test, y_test, f_05_score, cm, accuracy, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "final_models_list = []\n",
    "test_scores = []\n",
    "best_params = []\n",
    "confusion_mat = []\n",
    "class_met = []\n",
    "accuracy_scores = []\n",
    "final_models = []\n",
    "X_test_set_list =[]\n",
    "y_test_set_list =[]\n",
    "featname_list = []\n",
    "\n",
    "for i in range(10):\n",
    "    print(f'Random State # {i}')\n",
    "    print()\n",
    "    \n",
    "    fin_grid, X_test_set, y_test_set, test_score,cmat,acc, fname = ML_XGBpipeline_kfold(X, y, groups, 42*i , 4)\n",
    "    \n",
    "    #featname_list.append(featname)\n",
    "    \n",
    "    X_test_set_list.append(X_test_set)\n",
    "    \n",
    "    y_test_set_list.append(y_test_set)\n",
    "    \n",
    "    final_models_list.append(fin_grid)\n",
    "    \n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    confusion_mat.append(cmat)\n",
    "\n",
    "    accuracy_scores.append(acc)\n",
    "    \n",
    "    featname_list.append(fname)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the output so I can use it later\n",
    "import pickle\n",
    "\n",
    "file = open('XGB_grid.save', 'wb')\n",
    "\n",
    "pickle.dump((X_test_set_list, \n",
    "             y_test_set_list,\n",
    "             final_models_list,\n",
    "             test_scores,\n",
    "             confusion_mat,\n",
    "             accuracy_scores,\n",
    "             featname_list),file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Global Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Feature Importance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../results')\n",
    "file = open('XGB_grid.save', 'rb')\n",
    "X_test, y_test, model, f05, confusionmatrix, accuracy, ftr_names = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "\n",
    "X_test = X_test[0]\n",
    "y_test = y_test[0]\n",
    "grid = model[0]\n",
    "f05 = f05[0]\n",
    "confusionmatrix = confusionmatrix[0]\n",
    "accuracy  = accuracy[0]\n",
    "ftr_names  = ftr_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_[1].get_booster().feature_names = ftr_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../figures')\n",
    "import matplotlib.pyplot as plt\n",
    "metrics = [\"weight\", \"gain\", \"cover\", \"total_gain\", \"total_cover\"]\n",
    "\n",
    "for i in metrics:\n",
    "    a = grid.best_estimator_[1].get_booster().get_score(importance_type=i)\n",
    "    \n",
    "    sort = sorted( a.items(), key=lambda pair: pair[1], reverse=True )[:5]\n",
    "    \n",
    "    feat = []\n",
    "    metric_val = []\n",
    "    \n",
    "    for names, values in sort:\n",
    "        feat.append(names)\n",
    "        metric_val.append(values)\n",
    "\n",
    "    y_pos = np.arange(len(feat))\n",
    "        \n",
    "    plt.figure(figsize=(12,3))\n",
    "    plt.title(f\"Top 5 Features for Metric: {i}\", fontweight='bold', fontsize=22)\n",
    "    plt.barh(y_pos, metric_val)\n",
    "    plt.ylabel(\"Features\",fontsize=16)\n",
    "    plt.xlabel(\"Value\", fontsize=16)\n",
    "    plt.yticks(y_pos, feat, fontsize=16)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"XGB Feature Importance - \" + i +\".png\", format=\"PNG\", dpi=1200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
    "    \n",
    "for i_other,i_test in splitter.split(X, y, groups):\n",
    "    X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "    X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "    \n",
    "X_other_transformed = grid.best_estimator_[0].transform(X_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_other_transformed = pd.DataFrame(X_other_transformed)\n",
    "X_other_transformed.columns = ftr_names\n",
    "X_other_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    for i in range(1)\n",
    "\n",
    "    r = permutation_importance(grid.best_estimator_[1], X_test_transformed, y_test, \n",
    "                               n_repeats=30, random_state=42*i, scoring = 'accuracy')\n",
    "    \n",
    "    \n",
    "os.chdir('../results/Feature Importance Data')    \n",
    "file = open('XGB_PFI.save', 'wb')\n",
    "\n",
    "pickle.dump((r),file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../results/Feature Importance Data')  \n",
    "file = open('XGB_PFI.save', 'rb')\n",
    "r = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featnames = []\n",
    "feat_importances_mean = []\n",
    "feat_std = []\n",
    "\n",
    "\n",
    "for i in r.importances_mean.argsort()[-5:][::-1]:\n",
    "    featnames.append(ftr_names[i])\n",
    "    feat_importances_mean.append(r.importances_mean[i])\n",
    "    feat_std.append(r.importances_std[i])\n",
    "    \n",
    "    \n",
    "    print(f\"{ftr_names[i]:}: {r.importances_mean[i]:.3f}\"\n",
    "          f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')\n",
    "os.chdir('../figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuaize results\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.errorbar(featnames, feat_importances_mean, feat_std, fmt='o',ecolor = 'red',color='black',capsize = 4,)\n",
    "plt.title('XGBoost Permutation Feature Importance', fontweight = 'bold',fontsize=28)\n",
    "plt.ylabel(\"Decrease in test score\",fontsize=22)\n",
    "plt.xlabel(\"Feature\",fontsize=22)\n",
    "plt.xticks(fontsize=18, rotation=0)\n",
    "plt.yticks(fontsize=18, rotation=0)\n",
    "plt.savefig(\"XGBoost Permutation Feature Importance.png\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Global Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% time\n",
    "import shap\n",
    "shap.initjs() \n",
    "\n",
    "# explainer object with XGB model\n",
    "explainer = shap.TreeExplainer(grid.best_estimator_[1], data = X_other_transformed)\n",
    "\n",
    "# shape of test set\n",
    "print(np.shape(X_test_transformed))\n",
    "\n",
    "# calculate shap values on test set\n",
    "shap_values = explainer.shap_values(X_test_transformed)\n",
    "\n",
    "#shape of shape values\n",
    "print(np.shape(shap_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('XGB_SHAP_FI.save', 'wb')\n",
    "\n",
    "pickle.dump((explainer, shap_values),file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary plot\n",
    "#plt.figure(figsize=(20, 10))\n",
    "\n",
    "shap.summary_plot(shap_values, X_test_transformed, feature_names = ftr_names, max_display=5, plot_type=\"bar\", show=False)\n",
    "plt.gcf().set_size_inches(10, 5)\n",
    "plt.title('XGBoost SHAP Global Feature Importance', fontweight='bold',fontsize=20)\n",
    "plt.savefig('XGBoost SHAP Global Feature Importance.png', dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 42 # the index of the point to explain\n",
    "#print(explainer.expected_value[0]) # we explain class 0 predictions\n",
    "\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][index,:], \n",
    "                features = X_test_transformed[index,:],feature_names = ftr_names,show=True, link = 'logit')\n",
    "\n",
    "#plt.savefig('XGBoost SHAP Local Feature Importance Class 0', dpi=1200)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = 42 # the index of the point to explain\n",
    "print(explainer.expected_value[1]) # we explain class 1 predictions\n",
    "\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][index,:], \n",
    "                features = X_test_transformed[index,:],feature_names = ftr_names, link = 'logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 42 # the index of the point to explain\n",
    "print(explainer.expected_value[2]) # we explain class 2 predictions\n",
    "\n",
    "shap.force_plot(explainer.expected_value[2], shap_values[2][index,:], features = X_test_transformed[index,:],\n",
    "                feature_names = ftr_names, link = 'logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
