{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae537e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import xgboost\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import pickle\n",
    "from sklearn.inspection import permutation_importance\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a6198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('../data')\n",
    "\n",
    "\n",
    "X = pd.read_csv('X_3specialties_equalWeight_subsample.zip',compression='zip', index_col=False)\n",
    "y = pd.read_csv('y_3specialties_equalWeight_subsample.zip',compression='zip')\n",
    "groups = pd.read_csv('groups_3specialties_equalWeight_subsample.zip',compression='zip')\n",
    "\n",
    "X = X.iloc[:,1:]\n",
    "y = y.iloc[:,1:]\n",
    "groups = groups.iloc[:,1:]\n",
    "\n",
    "y_columns = y.columns\n",
    "\n",
    "#le = LabelEncoder()\n",
    "#y = y.values.ravel()\n",
    "#y = le.fit_transform(y)\n",
    "#y = pd.DataFrame(y)\n",
    "#y.columns = y_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_RFpipeline_kfold(X, y, groups, random_state,n_folds):\n",
    "    # create a test set\n",
    "    \n",
    "    splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=random_state)\n",
    "    \n",
    "    for i_other,i_test in splitter.split(X, y, groups):\n",
    "        X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "        X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]\n",
    "        \n",
    "    kf = GroupKFold(n_splits=n_folds)\n",
    "    \n",
    "    # create the pipeline: preprocessor + supervised ML method\n",
    "    \n",
    "    categorical_ftrs = ['Prscrbr_City','Prscrbr_State_Abrvtn','Brnd_Name','Gnrc_Name']\n",
    "\n",
    "    std_ftrs = ['Tot_Clms',  'Tot_30day_Fills', 'Tot_Day_Suply', 'Tot_Drug_Cst', \n",
    "                'Tot_Benes', 'GE65_Tot_Clms', 'GE65_Tot_30day_Fills', 'GE65_Tot_Drug_Cst',\n",
    "                'GE65_Tot_Day_Suply', 'GE65_Tot_Benes']\n",
    "\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(estimator = LinearRegression(), \n",
    "                                    random_state=random_state,max_iter=50)),\n",
    "    ('scaler', StandardScaler())])\n",
    "    \n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'))])\n",
    "    \n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('num', numeric_transformer, std_ftrs),\n",
    "        ('onehot', categorical_transformer, categorical_ftrs)],\n",
    "        remainder='passthrough')\n",
    "\n",
    "\n",
    "    pipe = make_pipeline(preprocessor,RandomForestClassifier())\n",
    "    \n",
    " \n",
    "    \n",
    "    # the parameter(s) we want to tune\n",
    "    \n",
    "    \n",
    "    param_grid = {'randomforestclassifier__max_depth': [1, 3, 10, 30,100, 300],\n",
    "                  'randomforestclassifier__min_samples_split': [16, 32, 64, 128],\n",
    "                  'randomforestclassifier__n_estimators': [1, 3, 10, 30, 100],\n",
    "                  'randomforestclassifier__random_state':[random_state]\n",
    "                 }\n",
    "    \n",
    "    \n",
    "    #f05_scorer = make_scorer(fbeta_score, beta=0.5, average = 'macro')\n",
    "    # prepare gridsearch\n",
    "    grid = GridSearchCV(pipe, \n",
    "                        param_grid=param_grid,\n",
    "                        scoring = 'accuracy',\n",
    "                        cv=kf, \n",
    "                        return_train_score = True, \n",
    "                        n_jobs=4, \n",
    "                        verbose=10)\n",
    "    \n",
    "    # do kfold CV on _other\n",
    "    \n",
    "    grid_result = grid.fit(X_other, y_other.values.ravel(), groups=groups_other)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #estimator = grid.best_estimator_\n",
    "    #print \"The features are:\", \n",
    "    \n",
    "    \n",
    "    feature_names = std_ftrs + list(grid.best_estimator_[0].named_transformers_['onehot'][0].get_feature_names(categorical_ftrs))\n",
    "    \n",
    "   # grid.best_estimator_.get_feature_names_out()\n",
    "    \n",
    "    print()\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    \n",
    "    print(f'Best params: {grid.best_params_}')\n",
    "    \n",
    "    #print(f\"mean CV: {means} +/ {stds}\")\n",
    "    \n",
    "    y_test_pred_proba = grid.predict_proba(X_test)\n",
    "    \n",
    "    y_test_pred = grid.predict(X_test)\n",
    "    \n",
    "    #score = accuracy_score(y_test,y_test_pred)\n",
    "    \n",
    "    f_05_score = fbeta_score(y_test, y_test_pred, beta = 0.5, labels=sorted(np.unique(y)), average='macro')\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    best_estimator = grid.best_estimator_\n",
    "    \n",
    "    #r = permutation_importance(best_estimator, X_test, y_test, n_repeats=30, random_state=random_state)\n",
    "    \n",
    "    print(\"f05:\", f_05_score)\n",
    "    print(\"accuracy:\", accuracy)\n",
    "    print()\n",
    "    return grid, np.array(feature_names), X_test, y_test, f_05_score, cm, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf761de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "final_models_list = []\n",
    "test_scores = []\n",
    "best_params = []\n",
    "confusion_mat = []\n",
    "class_met = []\n",
    "accuracy_scores = []\n",
    "final_models = []\n",
    "X_test_set_list =[]\n",
    "y_test_set_list =[]\n",
    "featname_list = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(f'Random State # {i}')\n",
    "    print()\n",
    "    \n",
    "    fin_grid, featnames, X_test_set, y_test_set, test_score, cmat, accuracy = ML_RFpipeline_kfold(X, y, groups, 42*i , 4)\n",
    "    \n",
    "    #featname_list.append(featname)\n",
    "    \n",
    "    X_test_set_list.append(X_test_set)\n",
    "    \n",
    "    y_test_set_list.append(y_test_set)\n",
    "    \n",
    "    final_models_list.append(fin_grid)\n",
    "    \n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    confusion_mat.append(cmat)\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    featname_list.append(featnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b7905",
   "metadata": {},
   "source": [
    "### Save the output for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30fa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "file = open('RF_grid.save', 'wb')\n",
    "\n",
    "pickle.dump((X_test_set_list, \n",
    "             y_test_set_list,\n",
    "             final_models_list,\n",
    "             test_scores,\n",
    "             confusion_mat,\n",
    "             accuracy_scores,\n",
    "             featname_list),file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2ef66",
   "metadata": {},
   "source": [
    "### Random Forest Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('RF_grid.save', 'rb')\n",
    "X_test, y_test, model, f05, confusionmatrix, accuracy, ftr_names = pickle.load(file)\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7aa931",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[0]\n",
    "y_test = y_test[0]\n",
    "grid = model[0]\n",
    "f05 = f05[0]\n",
    "confusionmatrix = confusionmatrix[0]\n",
    "accuracy  = accuracy[0]\n",
    "ftr_names  = ftr_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd60f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_RF = grid.best_estimator_[1].feature_importances_\n",
    "\n",
    "len(feature_importances_RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789179bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdi_importances = pd.Series(\n",
    "    feature_importances_RF, index=ftr_names).sort_values(ascending=True)\n",
    "\n",
    "mdi_importances_top10 = mdi_importances[-10:]\n",
    "mdi_importances_top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340cb158",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(mdi_importances_top10.index, mdi_importances_top10.values)\n",
    "plt.title(\"Random Forest Classifier Feature Importances\")\n",
    "plt.savefig(\"Random Forest Classifier Feature Importances.png\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66212e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f9cb4d",
   "metadata": {},
   "source": [
    "# Pertubation Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f8af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transform the test set\n",
    "X_test_transformed = grid.best_estimator_[0].transform(X_test)\n",
    "\n",
    "print(np.shape(X_test_transformed))\n",
    "\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "    r = permutation_importance(grid.best_estimator_[1], X_test_transformed, y_test, \n",
    "                               n_repeats=30, random_state=0, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a3edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "featnames = []\n",
    "feat_importances_mean = []\n",
    "feat_std = []\n",
    "\n",
    "\n",
    "for i in r.importances_mean.argsort()[-5:][::-1]:\n",
    "    featnames.append(ftr_names[i])\n",
    "    feat_importances_mean.append(r.importances_mean[i])\n",
    "    feat_std.append(r.importances_std[i])\n",
    "    \n",
    "    \n",
    "    print(f\"{ftr_names[i]:}: {r.importances_mean[i]:.3f}\"\n",
    "          f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('RF_PFI.save', 'wb')\n",
    "\n",
    "pickle.dump((r),file)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d152aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visuaize results\n",
    "\n",
    "sns.set(font_scale=1.2)\n",
    "plt.figure(figsize=(18, 5))\n",
    "plt.errorbar(featnames, feat_importances_mean, feat_std, fmt='o',ecolor = 'red',color='black',capsize = 4,)\n",
    "plt.title('Random Forest Permutation Feature Importance', fontweight = 'bold',fontsize=28)\n",
    "plt.ylabel(\"Decrease in model score\",fontsize=22)\n",
    "plt.xlabel(\"Feature\",fontsize=22)\n",
    "plt.xticks(fontsize=18, rotation=0)\n",
    "plt.yticks(fontsize=18, rotation=0)\n",
    "plt.savefig(\"Random Forest Permutation Feature Importance.png\", dpi=1200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5558c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_other_transformed = grid.best_estimator_[0].transform(X_other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6a4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = GroupShuffleSplit(n_splits=1,test_size=0.2,random_state=0)\n",
    "    \n",
    "for i_other,i_test in splitter.split(X, y, groups):\n",
    "    X_other, y_other, groups_other = X.iloc[i_other], y.iloc[i_other], groups.iloc[i_other]\n",
    "    X_test, y_test, groups_test = X.iloc[i_test], y.iloc[i_test], groups.iloc[i_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ee9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% time\n",
    "import shap\n",
    "shap.initjs() \n",
    "\n",
    "# explainer object with RF model\n",
    "explainer = shap.TreeExplainer(grid.best_estimator_[1], data = X_other_transformed, model_output='probability')\n",
    "\n",
    "# shape of test set\n",
    "print(np.shape(X_test_transformed))\n",
    "\n",
    "# calculate shap values on test set\n",
    "shap_values = explainer.shap_values(X_test_transformed)\n",
    "\n",
    "#shape of shape values\n",
    "print(np.shape(shap_values))\n",
    "\n",
    "\n",
    "# summary plot\n",
    "#shap.summary_plot(shap_values, X_test_transformed, feature_names = ftr_names, max_display=10, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac10462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test_transformed, feature_names = ftr_names, max_display=10, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7720193",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 42 # the index of the point to explain\n",
    "#print(explainer.expected_value[0]) # we explain class 0 predictions\n",
    "\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][index,:], \n",
    "                features = X_test_transformed[index,:],feature_names = ftr_names,show=True)\n",
    "\n",
    "#plt.savefig('XGBoost SHAP Local Feature Importance Class 0', dpi=1200)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25183ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 42 # the index of the point to explain\n",
    "print(explainer.expected_value[1]) # we explain class 0 predictions\n",
    "\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][index,:], \n",
    "                features = X_test_transformed[index,:],feature_names = ftr_names,show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef5678",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 42 # the index of the point to explain\n",
    "print(explainer.expected_value[2]) # we explain class 0 predictions\n",
    "\n",
    "shap.force_plot(explainer.expected_value[2], shap_values[2][index,:], features = X_test_transformed[index,:],\n",
    "                feature_names = ftr_names,show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj_env_win",
   "language": "python",
   "name": "proj_env_win"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
